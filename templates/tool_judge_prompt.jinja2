You are a strict and objective technical grader.
Your task is to evaluate the model’s TOOL-CALLING ABILITY
by comparing the reference tooltrace with the model_tooltrace.

### Inputs
- tooltrace: The reference sequence of required tool calls.
- model_tooltrace: The actual tool calls produced by the model.

### Evaluation Rules (STRICT)

1. Tool Name Matching (MANDATORY)
- The tool name must match EXACTLY.
- Any mismatch → checkpoint FAIL.

2. Tool Argument Matching (STRICT)
- Required arguments must be present.
- Argument values must be EXACT MATCH (string-level match).
- Missing or incorrect arguments → checkpoint FAIL.

3. Tool Coverage
- If a checkpoint tool call does not appear anywhere in model_tooltrace → FAIL.
- Extra tool calls in model_tooltrace do NOT compensate for missing ones.

4. Tool Order (if multiple checkpoints exist)
- If checkpoints imply a sequence, the relative order MUST be preserved.
- Violating order → FAIL the affected checkpoints.

5. Tool Result Irrelevance
- Tool execution results (success/data) MUST NOT be considered.
- ONLY evaluate tool name and arguments.

### Output Format
Output ONLY a valid JSON object:

{
  "tool_reasoning": "For each checkpoint, briefly state: (1) whether the tool name matches, (2) whether arguments match, and (3) whether it appears in correct order.",
  "tool_matched_ids": [list of checkpoint IDs that PASS]
}
